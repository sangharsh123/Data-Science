{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR7WUwXka5r_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "rY40xKHyczwR",
        "outputId": "626c956b-1fc7-46d9-97da-031bb9e57936"
      },
      "source": [
        "df= pd.read_csv(\"cancer_data.csv\")\n",
        "df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LohsxPQceJGj",
        "outputId": "aeec441f-7cc8-4ae1-96de-54ececc6d787"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
              "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
              "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
              "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
              "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeX6No93eQUJ",
        "outputId": "0f0ff639-0e87-45ff-9d87-adcb37972004"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "RF_hFs88eYuN",
        "outputId": "fc4c6eda-490b-4550-dbaa-cd4d9b2f5da4"
      },
      "source": [
        "sns.countplot(df['diagnosis'])\n",
        "B,M=df['diagnosis'].value_counts()\n",
        "print('Benign',B)\n",
        "print(\"Malignant\",M)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Benign 357\n",
            "Malignant 212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AinQt1alhtQ-"
      },
      "source": [
        "del df['Unnamed: 32']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROmeaNRVjI8W"
      },
      "source": [
        "X=df.iloc[:,2:].values\n",
        "y=df.iloc[:,1].values\n",
        "X_tolist = X.tolist()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W37Mm9tij-qY"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "labelencoder= LabelEncoder()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYfiI_72kA4L"
      },
      "source": [
        "y=labelencoder.fit_transform(y)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YwRg3qCkGW_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsEei8vFkRZR"
      },
      "source": [
        "x_train,x_test,y_train,y_test= train_test_split(X,y, test_size=0.2, random_state=100)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axLxWGrpkzhc"
      },
      "source": [
        "sc=StandardScaler()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R2A8cVTlO9t"
      },
      "source": [
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.transform(x_test)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oo3qxM3lYJs",
        "outputId": "a6ce0b18-100d-4f3d-b32a-01c7fee784ae"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.27914259,  0.01254364, -0.36045284, ..., -1.59146871,\n",
              "        -0.75525301, -1.19510832],\n",
              "       [-0.32838043,  2.26039928, -0.36509258, ..., -0.74909183,\n",
              "        -0.87172233, -0.64301263],\n",
              "       [ 0.50287016, -0.00850808,  0.67252257, ...,  1.57628782,\n",
              "         2.38420358,  1.2444247 ],\n",
              "       ...,\n",
              "       [-0.68173433, -0.51141023, -0.73627198, ..., -1.09828224,\n",
              "        -0.24765538, -0.8845907 ],\n",
              "       [-0.33417311, -0.29387581, -0.33598874, ..., -0.52480233,\n",
              "        -0.16421467, -0.25138966],\n",
              "       [-1.36671957, -1.25289851, -1.315818  , ..., -0.62872991,\n",
              "         1.40377528,  0.36501099]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ThXbcelb9c",
        "outputId": "3de4cd65-0889-45c5-e38a-01dca9adf29f"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc4wMPG_miXw"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nauP1w-HnT-t"
      },
      "source": [
        "#adding the input and first hiddeb layer\n",
        "classifier=Sequential()\n",
        "classifier.add( Dense(units=16,kernel_initializer='uniform', activation='relu', input_dim=30))\n",
        "classifier.add(Dense(units=16,kernel_initializer='uniform', activation='relu'))\n",
        "classifier.add(Dense(units=1,kernel_initializer='uniform',  activation='sigmoid'))\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHJKU9nJpWr8"
      },
      "source": [
        "classifier.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jNADAqyr4bZ",
        "outputId": "4f99799e-7e3a-4951-a3ec-426f8a619905"
      },
      "source": [
        "classifier.fit(x_train,y_train, batch_size=100,epochs=150)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4251\n",
            "Epoch 2/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.6869\n",
            "Epoch 3/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.7166\n",
            "Epoch 4/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.8096\n",
            "Epoch 5/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.8740\n",
            "Epoch 6/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.9248\n",
            "Epoch 7/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.9435\n",
            "Epoch 8/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.9188\n",
            "Epoch 9/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.9507\n",
            "Epoch 10/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.9490\n",
            "Epoch 11/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.9387\n",
            "Epoch 12/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.9258\n",
            "Epoch 13/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.9468\n",
            "Epoch 14/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.9357\n",
            "Epoch 15/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.9545\n",
            "Epoch 16/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.9334\n",
            "Epoch 17/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.9418\n",
            "Epoch 18/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.9396\n",
            "Epoch 19/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.9550\n",
            "Epoch 20/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.9535\n",
            "Epoch 21/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2365 - accuracy: 0.9618\n",
            "Epoch 22/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2090 - accuracy: 0.9664\n",
            "Epoch 23/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9607\n",
            "Epoch 24/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9660\n",
            "Epoch 25/150\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1822 - accuracy: 0.9541\n",
            "Epoch 26/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9651\n",
            "Epoch 27/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1387 - accuracy: 0.9752\n",
            "Epoch 28/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1386 - accuracy: 0.9684\n",
            "Epoch 29/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9738\n",
            "Epoch 30/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9754\n",
            "Epoch 31/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9783\n",
            "Epoch 32/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9756\n",
            "Epoch 33/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9692\n",
            "Epoch 34/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.9689\n",
            "Epoch 35/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9719\n",
            "Epoch 36/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9719\n",
            "Epoch 37/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9775\n",
            "Epoch 38/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9785\n",
            "Epoch 39/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.9792\n",
            "Epoch 40/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9796\n",
            "Epoch 41/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9753\n",
            "Epoch 42/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9809\n",
            "Epoch 43/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9784\n",
            "Epoch 44/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9823\n",
            "Epoch 45/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9830\n",
            "Epoch 46/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9843\n",
            "Epoch 47/150\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0706 - accuracy: 0.9808\n",
            "Epoch 48/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9854\n",
            "Epoch 49/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9836\n",
            "Epoch 50/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9903\n",
            "Epoch 51/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9849\n",
            "Epoch 52/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9772\n",
            "Epoch 53/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9833\n",
            "Epoch 54/150\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9864\n",
            "Epoch 55/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9831\n",
            "Epoch 56/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9859\n",
            "Epoch 57/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9863\n",
            "Epoch 58/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9866\n",
            "Epoch 59/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9881\n",
            "Epoch 60/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9867\n",
            "Epoch 61/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9866\n",
            "Epoch 62/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9813\n",
            "Epoch 63/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9880\n",
            "Epoch 64/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9853\n",
            "Epoch 65/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9833\n",
            "Epoch 66/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9800\n",
            "Epoch 67/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9813\n",
            "Epoch 68/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9832\n",
            "Epoch 69/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9861\n",
            "Epoch 70/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9841\n",
            "Epoch 71/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9898\n",
            "Epoch 72/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9862\n",
            "Epoch 73/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9880\n",
            "Epoch 74/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9871\n",
            "Epoch 75/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9869\n",
            "Epoch 76/150\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9869\n",
            "Epoch 77/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9869\n",
            "Epoch 78/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9789\n",
            "Epoch 79/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9870\n",
            "Epoch 80/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9863\n",
            "Epoch 81/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9872\n",
            "Epoch 82/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9897\n",
            "Epoch 83/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9911\n",
            "Epoch 84/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9865\n",
            "Epoch 85/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9883\n",
            "Epoch 86/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9956\n",
            "Epoch 87/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9921\n",
            "Epoch 88/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9924\n",
            "Epoch 89/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9910\n",
            "Epoch 90/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9930\n",
            "Epoch 91/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9962\n",
            "Epoch 92/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9912\n",
            "Epoch 93/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9914\n",
            "Epoch 94/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9921\n",
            "Epoch 95/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9929\n",
            "Epoch 96/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9943\n",
            "Epoch 97/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9874\n",
            "Epoch 98/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9964\n",
            "Epoch 99/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9941\n",
            "Epoch 100/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9916\n",
            "Epoch 101/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9924\n",
            "Epoch 102/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9921\n",
            "Epoch 103/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9916\n",
            "Epoch 104/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9924\n",
            "Epoch 105/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9934\n",
            "Epoch 106/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9932\n",
            "Epoch 107/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9954\n",
            "Epoch 108/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9925\n",
            "Epoch 109/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9924\n",
            "Epoch 110/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9974\n",
            "Epoch 111/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9925\n",
            "Epoch 112/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9934\n",
            "Epoch 113/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9946\n",
            "Epoch 114/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9970\n",
            "Epoch 115/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9946\n",
            "Epoch 116/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9954\n",
            "Epoch 117/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9942\n",
            "Epoch 118/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9916\n",
            "Epoch 119/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9921\n",
            "Epoch 120/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9916\n",
            "Epoch 121/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9921\n",
            "Epoch 122/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9938\n",
            "Epoch 123/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9929\n",
            "Epoch 124/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9907\n",
            "Epoch 125/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9934\n",
            "Epoch 126/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9916\n",
            "Epoch 127/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9932\n",
            "Epoch 128/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9946\n",
            "Epoch 129/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9907\n",
            "Epoch 130/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9932\n",
            "Epoch 131/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9954\n",
            "Epoch 132/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9939\n",
            "Epoch 133/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9938\n",
            "Epoch 134/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9952\n",
            "Epoch 135/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9924\n",
            "Epoch 136/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9946\n",
            "Epoch 137/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9960\n",
            "Epoch 138/150\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9904\n",
            "Epoch 139/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9942\n",
            "Epoch 140/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9954\n",
            "Epoch 141/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9934\n",
            "Epoch 142/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9968\n",
            "Epoch 143/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9935\n",
            "Epoch 144/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9904\n",
            "Epoch 145/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9946\n",
            "Epoch 146/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9899\n",
            "Epoch 147/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9946\n",
            "Epoch 148/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9964\n",
            "Epoch 149/150\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9938\n",
            "Epoch 150/150\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f417c3a2850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar-2SayJsFur"
      },
      "source": [
        "y_pred=classifier.predict(x_test)\n",
        "y_pred=(y_pred>0.5)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_HAV_GsstdH"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL4GW5Fas2OD"
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MytuRbC5s8R0",
        "outputId": "0c6c12a2-0ed9-419b-beaa-682722074dee"
      },
      "source": [
        "sns.heatmap(cm, annot=True)\n",
        "plt.savefig('h.png')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8R8MhKatKKt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}